{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Conv1D, Reshape,Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(in_shape=(2475,4)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 10, strides=2, padding='same', input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=wasserstein_loss, optimizer='Adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(in_shape=(30,30,3)):\n",
    "    model = Sequential()   \n",
    "    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Reshape((225,1,32)))\n",
    "    model.add(Conv2DTranspose(32,(3,3),strides=(11,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Reshape((2475,32)))\n",
    "    model.add(Conv1D(4, 5, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    return model\n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(generator, discriminator):\n",
    "    for layer in discriminator.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    model=Sequential() \n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss=wasserstein_loss, optimizer='Adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reals():\n",
    "    real=pd.read_csv('Producer_start_center_hetrogenous.csv')\n",
    "    real=np.array(real[['WOPR1','WOPR2','WWPR1','WWPR2']].astype('float32'))\n",
    "    X=np.zeros((400,2560,4))\n",
    "    for i in range(400):\n",
    "        X[i,:,:]=real[2560*i:2560*(1+i),:]\n",
    "    \n",
    "    return X\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(n_samples):\n",
    "    x_input = randn(30*30 * n_samples)\n",
    "    x_input = x_input.reshape(n_samples,30,30)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs():\n",
    "    real=pd.read_csv('Producer_start_center_hetrogenous.csv')\n",
    "    real=np.array(real[['X_loc','Y_loc']].astype('float32'))\n",
    "    input=np.zeros((400,30,30,2))\n",
    "    for i in range(400):\n",
    "        x=int(real[2560*i,0]-1)\n",
    "        input[i,x,:,0]=1\n",
    "        y=int(real[2560*i,1]-1)\n",
    "        input[i,:,y,1]=1  \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs(input,noise,ix):\n",
    "    \n",
    "    input1=np.zeros((400,30,30,3))\n",
    "       \n",
    "    input1[:,:,:,0:2]=input\n",
    "    input1=input1[ix]\n",
    "    for i in range(len(ix)):\n",
    "        input1[i,:,:,2]=noise[i,:,:]\n",
    "    \n",
    "    return input1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset,ix,n_samples):\n",
    "    X=dataset[ix]\n",
    "    y=np.ones(n_samples)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator,ix,n_samples,input):\n",
    "    noise=generate_noise(n_samples)\n",
    "    x_input = generate_inputs(input,noise,ix)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros(n_samples)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan_model, dataset, n_epochs=10, n_samples=16,n_disc=5):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_samples)\n",
    "    n_steps=bat_per_epo*n_epochs\n",
    "    half_batch = int(n_samples / 2)\n",
    "    disc1_hist, disc2_hist, gan_hist = list(), list(), list()\n",
    "    for i in range(n_steps):\n",
    "        disc1_tmp, disc2_tmp = list(), list()\n",
    "        for j in range(n_disc):\n",
    "            ix=randint(0, dataset.shape[0], half_batch)\n",
    "            X_real, y_real = generate_real_samples(dataset,ix,half_batch)\n",
    "            disc_loss1 = discriminator.train_on_batch(X_real, y_real)\n",
    "            disc1_tmp.append(disc_loss1)\n",
    "            X_fake, y_fake = generate_fake_samples(generator,ix,half_batch,input)\n",
    "            disc_loss2 = discriminator.train_on_batch(X_fake, y_fake)\n",
    "            disc1_tmp.append(disc_loss2)\n",
    "        disc1_hist.append(mean(disc1_tmp))\n",
    "        disc2_hist.append(mean(disc2_tmp))\n",
    "        ix=randint(0, dataset.shape[0], n_samples)\n",
    "        noise=generate_noise(n_samples)\n",
    "        X_gan = generate_inputs(input,noise,ix)\n",
    "        y_gan= np.zeros(n_samples)\n",
    "        gan_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        gan_hist.append(gan_loss)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2560, 4)\n",
      "(400, 30, 30, 2)\n",
      "discriminator:\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1238, 64)          2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1238, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1238, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 79232)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 79233     \n",
      "=================================================================\n",
      "Total params: 82,113\n",
      "Trainable params: 81,985\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "generator:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 225, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 2475, 1, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2475, 1, 32)       128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 2475, 1, 32)       0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2475, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2475, 4)           644       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2475, 4)           16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 2475, 4)           0         \n",
      "=================================================================\n",
      "Total params: 30,676\n",
      "Trainable params: 30,412\n",
      "Non-trainable params: 264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dataset=load_reals()\n",
    "input=inputs()\n",
    "print(dataset.shape)\n",
    "print(input.shape)\n",
    "discriminator=discriminator(in_shape=(2475,4))\n",
    "print('discriminator:')\n",
    "discriminator.summary()\n",
    "generator=generator(in_shape=(30,30,3))\n",
    "print('generator:')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2475, 4)\n"
     ]
    }
   ],
   "source": [
    "## make the dimensions same \n",
    "dataset=dataset[:,0:2475,:]\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model=gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_3 (Sequential)    (None, 2475, 4)           30676     \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 82113     \n",
      "=================================================================\n",
      "Total params: 112,789\n",
      "Trainable params: 30,540\n",
      "Non-trainable params: 82,249\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, gan_model, dataset, n_epochs=10, n_samples=16,n_disc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
